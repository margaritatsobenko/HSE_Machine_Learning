{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Qp0H_zUQuu_"
   },
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[ML][HW05] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "22ezVRf3QuvA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.datasets import make_blobs, make_moons\n",
    "from typing import List, NoReturn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4qfDPH_LQuvF"
   },
   "source": [
    "### Задание 1 (3 балла)\n",
    "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
    "\n",
    "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
    "\n",
    "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
    "\n",
    "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
    "\n",
    "\n",
    "#### Методы\n",
    "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
    "\n",
    "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
    "\n",
    "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "RWFLlHqaYbgC"
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    \"\"\"\n",
    "    Абстрактный класс. Его менять не нужно.\n",
    "    \"\"\"\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, d):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def update(self, alpha):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "aYS2gE4PYepZ"
   },
   "outputs": [],
   "source": [
    "class Linear(Module):\n",
    "    \"\"\"\n",
    "    Линейный полносвязный слой.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_features: int, out_features: int):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        in_features : int\n",
    "            Размер входа.\n",
    "        out_features : int \n",
    "            Размер выхода.\n",
    "    \n",
    "        Notes\n",
    "        -----\n",
    "        W и b инициализируются случайно.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.W = np.random.rand(in_features, out_features)\n",
    "        self.b = np.zeros((1, out_features))\n",
    "        \n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = Wx + b.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "            То есть, либо x вектор с in_features элементов,\n",
    "            либо матрица размерности (batch_size, in_features).\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя.\n",
    "            Либо вектор с out_features элементами,\n",
    "            либо матрица размерности (batch_size, out_features)\n",
    "\n",
    "        \"\"\"\n",
    "        self.X = np.copy(x)\n",
    "        self.Z = self.X @ self.W + self.b\n",
    "        \n",
    "        return self.Z\n",
    "    \n",
    "    def backward(self, d: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        self.W_g = self.X.T @ d\n",
    "        self.b_g = np.sum(d, axis = 0)\n",
    "        \n",
    "        return d @ self.W.T\n",
    "        \n",
    "    def update(self, alpha: float) -> NoReturn:\n",
    "        \"\"\"\n",
    "        Обновляет W и b с заданной скоростью обучения.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        alpha : float\n",
    "            Скорость обучения.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.W -= alpha * self.W_g\n",
    "        self.b -= alpha * self.b_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "94hkbnD1QuvG"
   },
   "outputs": [],
   "source": [
    "class ReLU(Module):\n",
    "    \"\"\"\n",
    "    Слой, соответствующий функции активации ReLU.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = max(0, x).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя (той же размерности, что и вход).\n",
    "\n",
    "        \"\"\"\n",
    "        self.m = x >= 0\n",
    "        return x * self.m\n",
    "        \n",
    "    def backward(self, d) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        return d * self.m\n",
    "        \n",
    "        \n",
    "class Softmax(Module):\n",
    "    \"\"\"\n",
    "    Слой, соответствующий функции активации Softmax.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Возвращает y = Softmax(x).\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : np.ndarray\n",
    "            Входной вектор или батч.\n",
    "    \n",
    "        Return\n",
    "        ------\n",
    "        y : np.ndarray\n",
    "            Выход после слоя (той же размерности, что и вход).\n",
    "\n",
    "        \"\"\"\n",
    "        num = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "        den = np.sum(num, axis=1, keepdims=True)\n",
    "        self.out = num / den\n",
    "        \n",
    "        return self.out\n",
    "        \n",
    "    def backward(self, d) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Cчитает градиент при помощи обратного распространения ошибки.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        d : np.ndarray\n",
    "            Градиент.\n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Новое значение градиента.\n",
    "        \"\"\"\n",
    "        res = self.out\n",
    "        n = len(res)\n",
    "        res[range(n), d] -= 1\n",
    "        \n",
    "        return res / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rb_ip_h8QuvJ"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь сделаем саму нейронную сеть.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
    "\n",
    "`epochs` - количество эпох обучения\n",
    "\n",
    "`alpha` - скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Q_JFCizKQuvK"
   },
   "outputs": [],
   "source": [
    "class MLPClassifier:\n",
    "    def __init__(self, modules: List[Module], epochs: int = 40, alpha: float = 0.01):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        modules : List[Module]\n",
    "            Cписок, состоящий из ранее реализованных модулей и \n",
    "            описывающий слои нейронной сети. \n",
    "            В конец необходимо добавить Softmax.\n",
    "        epochs : int\n",
    "            Количество эпох обучения\n",
    "        alpha : float\n",
    "            Cкорость обучения.\n",
    "        \"\"\"\n",
    "        self.modules = modules\n",
    "        self.modules.append(Softmax())\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "     \n",
    "    def _forward(self, X):\n",
    "        res = X\n",
    "        \n",
    "        for m in self.modules:\n",
    "            res = m.forward(res)\n",
    "            \n",
    "        return res\n",
    "    \n",
    "    def _backward(self, y):\n",
    "        res = y\n",
    "        \n",
    "        for m in reversed(self.modules):\n",
    "            res = m.backward(res)\n",
    "            \n",
    "            if isinstance(m, Linear):\n",
    "                m.update(self.alpha)   \n",
    "                \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray, batch_size=32) -> NoReturn:\n",
    "        \"\"\"\n",
    "        Обучает нейронную сеть заданное число эпох. \n",
    "        В каждой эпохе необходимо использовать cross-entropy loss для обучения, \n",
    "        а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для обучения.\n",
    "        y : np.ndarray\n",
    "            Вектор меток классов для данных.\n",
    "        batch_size : int\n",
    "            Размер батча.\n",
    "        \"\"\"\n",
    "        y = np.array(y)\n",
    "        n = X.shape[0]\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            ids = np.random.permutation(n)\n",
    "            X_perm = X[ids, :]\n",
    "            y_perm = y[ids]\n",
    "            cur_id = 0\n",
    "            \n",
    "            while cur_id < n:\n",
    "                X_batch = X_perm[cur_id : cur_id + batch_size, :]\n",
    "                y_batch = y_perm[cur_id : cur_id + batch_size]\n",
    "                \n",
    "                _ = self._forward(X_batch)\n",
    "                \n",
    "                self._backward(y_batch)\n",
    "                \n",
    "                cur_id = cur_id + batch_size            \n",
    "\n",
    "            \n",
    "    def predict_proba(self, X: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Предсказывает вероятности классов для элементов X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Предсказанные вероятности классов для всех элементов X.\n",
    "            Размерность (X.shape[0], n_classes)\n",
    "        \n",
    "        \"\"\"\n",
    "        return self._forward(X)\n",
    "        \n",
    "    def predict(self, X) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Предсказывает метки классов для элементов X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : np.ndarray\n",
    "            Данные для предсказания.\n",
    "        \n",
    "        Return\n",
    "        ------\n",
    "        np.ndarray\n",
    "            Вектор предсказанных классов\n",
    "        \n",
    "        \"\"\"\n",
    "        p = self.predict_proba(X)\n",
    "        return np.argmax(p, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "onDymYQXQuvN"
   },
   "outputs": [],
   "source": [
    "p = MLPClassifier([\n",
    "    Linear(4, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 2)\n",
    "])\n",
    "\n",
    "X = np.random.randn(50, 4)\n",
    "y = [(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X]\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3C1EIsDqQuvQ"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
    "\n",
    "#### Оценка\n",
    "Accuracy на первом датасете больше 0.85 - +1 балл\n",
    "\n",
    "Accuracy на втором датасете больше 0.85 - +1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "d5UAgXTcQuvQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.96\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons(400, noise=0.075)\n",
    "X_test, y_test = make_moons(400, noise=0.075)\n",
    "\n",
    "best_acc = 0\n",
    "for _ in range(25):\n",
    "    p = MLPClassifier([\n",
    "        Linear(2, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 2)])\n",
    "\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "MMDJM4qFQuvT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9475\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "best_acc = 0\n",
    "for _ in range(25):\n",
    "    p = MLPClassifier([\n",
    "        Linear(2, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 64),\n",
    "        ReLU(),\n",
    "        Linear(64, 3)])\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nPbVTFnMQuvW"
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "tV0mJLu-QuvX"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VUC_QqpAQuva"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = transforms.ToTensor()\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
    "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGmpjcFfQuvd"
   },
   "source": [
    "### Задание 4 (3 балла)\n",
    "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
    "\n",
    "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
    "\n",
    "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
    "\n",
    "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "5sRmTKwKQuve"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
    "        self.fc1 = nn.Linear(16 * 6 * 6, 128)\n",
    "        self.fc2 = nn.Linear(128, 128)\n",
    "        self.fc3 = nn.Linear(128, 10)\n",
    "        \n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "  \n",
    "\n",
    "    \n",
    "cr = nn.CrossEntropyLoss()\n",
    "\n",
    "def calculate_loss(X: torch.Tensor, y: torch.Tensor, model: Model):\n",
    "    \"\"\"\n",
    "    Cчитает cross-entropy.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : torch.Tensor\n",
    "        Данные для обучения.\n",
    "    y : torch.Tensor\n",
    "        Метки классов.\n",
    "    model : Model\n",
    "        Модель, которую будем обучать.\n",
    "\n",
    "    \"\"\"\n",
    "    return cr(model(X), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAsLmkUqQuvh"
   },
   "source": [
    "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "k5G8iMCeQuvh"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs=65):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(epochs):\n",
    "        #Train\n",
    "        loss_mean = 0\n",
    "        elements = 0\n",
    "        for X, y in iter(train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        train_losses.append(loss_mean / elements)\n",
    "        #Test\n",
    "        loss_mean = 0 \n",
    "        elements = 0\n",
    "        for X, y in iter(test_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        test_losses.append(loss_mean / elements)\n",
    "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vmD9eWJOQuvl",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss 2.108387258796692 | Test loss 1.904183200454712\n",
      "Epoch 1 | Train loss 1.811185245742798 | Test loss 1.7185433839797974\n",
      "Epoch 2 | Train loss 1.6718988015365601 | Test loss 1.6234712749481202\n",
      "Epoch 3 | Train loss 1.5809777836227417 | Test loss 1.5525624010086059\n",
      "Epoch 4 | Train loss 1.5297480378723145 | Test loss 1.5127240156173707\n",
      "Epoch 5 | Train loss 1.4930685457992554 | Test loss 1.4796517915725709\n",
      "Epoch 6 | Train loss 1.454495368232727 | Test loss 1.443462978553772\n",
      "Epoch 7 | Train loss 1.433333837966919 | Test loss 1.4483224384307862\n",
      "Epoch 8 | Train loss 1.4095536233520507 | Test loss 1.4057226457595826\n",
      "Epoch 9 | Train loss 1.3909869741821288 | Test loss 1.3857332773208617\n",
      "Epoch 10 | Train loss 1.374558176612854 | Test loss 1.3688387943267821\n",
      "Epoch 11 | Train loss 1.3493974461364746 | Test loss 1.3524514507293701\n",
      "Epoch 12 | Train loss 1.336366692314148 | Test loss 1.348775167274475\n",
      "Epoch 13 | Train loss 1.3242014934921265 | Test loss 1.3348827014923095\n",
      "Epoch 14 | Train loss 1.302429787788391 | Test loss 1.3214598503112793\n",
      "Epoch 15 | Train loss 1.290378672103882 | Test loss 1.3061841201782227\n",
      "Epoch 16 | Train loss 1.281197359046936 | Test loss 1.296367660331726\n",
      "Epoch 17 | Train loss 1.2599233309555053 | Test loss 1.2880079582214357\n",
      "Epoch 18 | Train loss 1.2467443928527833 | Test loss 1.2608168397903443\n",
      "Epoch 19 | Train loss 1.2318519735717774 | Test loss 1.2555676830291749\n",
      "Epoch 20 | Train loss 1.2213788473510743 | Test loss 1.2620376113891603\n",
      "Epoch 21 | Train loss 1.2119628814315795 | Test loss 1.2366378665924072\n",
      "Epoch 22 | Train loss 1.1918707032394409 | Test loss 1.2278379276275635\n",
      "Epoch 23 | Train loss 1.18022930267334 | Test loss 1.217891212463379\n",
      "Epoch 24 | Train loss 1.1682126746749877 | Test loss 1.222922366142273\n",
      "Epoch 25 | Train loss 1.155621756401062 | Test loss 1.218688694190979\n",
      "Epoch 26 | Train loss 1.151246736793518 | Test loss 1.2054218465805053\n",
      "Epoch 27 | Train loss 1.1400700913238526 | Test loss 1.1833707298278808\n",
      "Epoch 28 | Train loss 1.1237194785690308 | Test loss 1.1841381029129028\n",
      "Epoch 29 | Train loss 1.118319356956482 | Test loss 1.1739893991470336\n",
      "Epoch 30 | Train loss 1.1042106866073609 | Test loss 1.1614945363998412\n",
      "Epoch 31 | Train loss 1.094990454750061 | Test loss 1.181664740562439\n",
      "Epoch 32 | Train loss 1.0939544710540772 | Test loss 1.1645919101715088\n",
      "Epoch 33 | Train loss 1.0823655387496949 | Test loss 1.1438905820846557\n",
      "Epoch 34 | Train loss 1.0706938888931274 | Test loss 1.1422777952194214\n",
      "Epoch 35 | Train loss 1.0726997065353394 | Test loss 1.1465370723724366\n",
      "Epoch 36 | Train loss 1.0514862878799438 | Test loss 1.134134688949585\n",
      "Epoch 37 | Train loss 1.050016104927063 | Test loss 1.1455360067367553\n",
      "Epoch 38 | Train loss 1.0405828579330445 | Test loss 1.1344280324935914\n",
      "Epoch 39 | Train loss 1.031365690612793 | Test loss 1.1138512689590454\n",
      "Epoch 40 | Train loss 1.0260491143035888 | Test loss 1.1317842960357667\n",
      "Epoch 41 | Train loss 1.0176932567596435 | Test loss 1.1187107929229736\n",
      "Epoch 42 | Train loss 1.0093803894424438 | Test loss 1.1205398502349853\n",
      "Epoch 43 | Train loss 1.0111782697868348 | Test loss 1.103811812019348\n",
      "Epoch 44 | Train loss 0.9986607524871827 | Test loss 1.1171877464294433\n",
      "Epoch 45 | Train loss 0.9988621201705933 | Test loss 1.109732353401184\n",
      "Epoch 46 | Train loss 1.0043513320159911 | Test loss 1.1092114873886108\n",
      "Epoch 47 | Train loss 0.9798602004623413 | Test loss 1.0967341346740722\n",
      "Epoch 48 | Train loss 0.9734824470520019 | Test loss 1.1011908588409425\n",
      "Epoch 49 | Train loss 0.9687929545974732 | Test loss 1.099201854324341\n",
      "Epoch 50 | Train loss 0.9607414530181885 | Test loss 1.1106926794052123\n",
      "Epoch 51 | Train loss 0.9533712246322632 | Test loss 1.097141224861145\n",
      "Epoch 52 | Train loss 0.9568251461601257 | Test loss 1.1217518617630005\n",
      "Epoch 53 | Train loss 0.9510519272041321 | Test loss 1.095850060081482\n",
      "Epoch 54 | Train loss 0.940639730129242 | Test loss 1.0861004852294922\n",
      "Epoch 55 | Train loss 0.9358940604782104 | Test loss 1.0930904003143311\n",
      "Epoch 56 | Train loss 0.9283238600730896 | Test loss 1.087894669151306\n",
      "Epoch 57 | Train loss 0.9220154273796082 | Test loss 1.0767845689773559\n",
      "Epoch 58 | Train loss 0.9268617124557496 | Test loss 1.0782625961303711\n",
      "Epoch 59 | Train loss 0.9178990759468079 | Test loss 1.0864068361282349\n",
      "Epoch 60 | Train loss 0.9084198463439941 | Test loss 1.089296968460083\n",
      "Epoch 61 | Train loss 0.9000803512954711 | Test loss 1.071627675819397\n",
      "Epoch 62 | Train loss 0.8950933096122742 | Test loss 1.083237615776062\n",
      "Epoch 63 | Train loss 0.899328515663147 | Test loss 1.0886586009979249\n",
      "Epoch 64 | Train loss 0.8866186368751526 | Test loss 1.111541050338745\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(device)\n",
    "train_l, test_l = train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJNAuHjNQuvn"
   },
   "source": [
    "Построим график функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "F6OEGqriQuvo"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
    "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "miUxg0bDQuvs"
   },
   "source": [
    "И, наконец, посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "UXSOJFI8Quvt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy 0.6138\n",
      "Precision [0.68743616 0.75977654 0.48365385 0.49352332 0.54084507 0.63055062\n",
      " 0.59286776 0.70752688 0.61706949 0.64180479]\n",
      "Recall [0.673 0.68  0.503 0.381 0.576 0.355 0.798 0.658 0.817 0.697]\n",
      "Mean Precision 0.6155054462621206\n",
      "Mean Recall 0.6138000000000001\n"
     ]
    }
   ],
   "source": [
    "true_positive = np.zeros(10)\n",
    "true_negative = np.zeros(10)\n",
    "false_positive = np.zeros(10)\n",
    "false_negative = np.zeros(10)\n",
    "accuracy = 0\n",
    "ctn = 0\n",
    "for X, y in iter(test_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X).max(dim=1)[1]\n",
    "    for i in range(10):\n",
    "        for pred, real in zip(y_pred, y):\n",
    "            if real == i:\n",
    "                if pred == real:\n",
    "                    true_positive[i] += 1\n",
    "                else:\n",
    "                    false_negative[i] += 1\n",
    "            else:\n",
    "                if pred == i:\n",
    "                    false_positive[i] += 1\n",
    "                else:\n",
    "                    true_negative[i] += 1\n",
    "            \n",
    "    accuracy += torch.sum(y_pred == y).item()\n",
    "    ctn += len(y)\n",
    "print(\"Overall accuracy\", accuracy / ctn)\n",
    "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
    "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
    "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
    "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw05_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
